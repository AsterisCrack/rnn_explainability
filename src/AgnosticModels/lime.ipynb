{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.jit import RecursiveScriptModule\n",
    "\n",
    "# other libraries\n",
    "from typing import Final\n",
    "\n",
    "# own modules\n",
    "from src.RNNModelTrain.data import load_data\n",
    "from src.RNNModelTrain.utils import set_seed\n",
    "#from src.RNNModelTrain.train_functions import t_step\n",
    "\n",
    "\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static variables\n",
    "DATA_PATH: Final[str] = \"NLP_Data/data\"\n",
    "NUM_CLASSES: Final[int] = 10\n",
    "\n",
    "# set device\n",
    "device = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model: RecursiveScriptModule = torch.jit.load(\"models/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pablo\\Desktop\\IMAT\\Tercero\\NaturalLanguageProcessing\\rnn_explainability\\src\\RNNModelTrain\\data.py:62: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['tag'] = data['tag'].replace('bot', 1)\n",
      "c:\\Users\\pablo\\Desktop\\IMAT\\Tercero\\NaturalLanguageProcessing\\rnn_explainability\\src\\RNNModelTrain\\data.py:62: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['tag'] = data['tag'].replace('bot', 1)\n",
      "c:\\Users\\pablo\\Desktop\\IMAT\\Tercero\\NaturalLanguageProcessing\\rnn_explainability\\src\\RNNModelTrain\\data.py:62: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['tag'] = data['tag'].replace('bot', 1)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "train_dataloader: DataLoader\n",
    "val_dataloader: DataLoader\n",
    "test_dataloader: DataLoader\n",
    "mean_price: float\n",
    "std_price: float\n",
    "(\n",
    "    train_dataloader, val_dataloader, test_dataloader\n",
    ") = load_data(save_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x [batch_size, seq_length, input_dim]: torch.Size([64, 41])\n",
      "Shape of y [batch_size]: torch.Size([64])\n",
      "tensor([  20,   47,  315,   27,  464, 4153, 1075,   20,   47,  159,   58,   43,\n",
      "         153,   20,   47,   13,  315,  528, 4153, 1075, 1792,  159,   43, 1841,\n",
      "           8,   20,   47,   13,   58,   38,   47,   13,   20,   23,  888,   96,\n",
      "           3,    4,   13,   11,  132])\n"
     ]
    }
   ],
   "source": [
    "# Print some example data\n",
    "for x, y, _ in train_dataloader:\n",
    "    print(\"Shape of x [batch_size, seq_length, input_dim]:\", x.shape)\n",
    "    print(\"Shape of y [batch_size]:\", y.shape)\n",
    "    \n",
    "    print(x[0])\n",
    "    break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# evaluate the model\n",
    "test_results = t_step(model, test_dataloader,\n",
    "                        mean_price, std_price, device)\n",
    "\n",
    "# print the test resulsts\n",
    "print(f\"MAE test loss: {test_results}\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the model with LIME:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([])\n",
    "y_train = np.array([])\n",
    "for x, y, _ in train_dataloader:\n",
    "    X_train = np.append(X_train, x)\n",
    "    y_train = np.append(y_train, y)\n",
    "    \n",
    "X_test = np.array([])\n",
    "y_test = np.array([])\n",
    "for x, y, _ in test_dataloader:\n",
    "    X_test = np.append(X_test, x)\n",
    "    y_test = np.append(y_test, y)\n",
    "    \n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mlime_tabular\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecurrentTabularExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mdiscretize_continuous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFalling\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRising\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mdiscretizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdecile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\Desktop\\IMAT\\Tercero\\NaturalLanguageProcessing\\rnn_explainability\\env\\lib\\site-packages\\lime\\lime_tabular.py:615\u001b[0m, in \u001b[0;36mRecurrentTabularExplainer.__init__\u001b[1;34m(self, training_data, mode, training_labels, feature_names, categorical_features, categorical_names, kernel_width, kernel, verbose, class_names, feature_selection, discretize_continuous, discretizer, random_state)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;124;03m    training_data: numpy 3d array with shape\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;124;03m        initialized using the internal numpy seed.\u001b[39;00m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;66;03m# Reshape X\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m n_samples, n_timesteps, n_features \u001b[38;5;241m=\u001b[39m training_data\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    616\u001b[0m training_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(training_data, axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[0;32m    617\u001b[0m         n_samples, n_timesteps \u001b[38;5;241m*\u001b[39m n_features)\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_timesteps \u001b[38;5;241m=\u001b[39m n_timesteps\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "explainer = lime_tabular.RecurrentTabularExplainer(X_train, training_labels=y_train, feature_names=data_columns,\n",
    "                                                   discretize_continuous=True,\n",
    "                                                   class_names=['Falling', 'Rising'],\n",
    "                                                   discretizer='decile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test[50], model.predict, num_features=10, labels=(1,))\n",
    "exp.show_in_notebook()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
